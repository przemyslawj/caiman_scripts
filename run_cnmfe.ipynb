{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import scipy.io as sio\n",
    "import re\n",
    "import os\n",
    "import h5py\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import logging\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('default')\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "import smtplib\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.visualization import inspect_correlation_pnr\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "import peakutils\n",
    "\n",
    "\"\"\"# Prepare data\"\"\"\n",
    "\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False, ignore_preexisting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Motion Corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data_dir = '/home/prez/data/2019-08/habituation/2019-08-27/caiman/E-BL/'\n",
    "\n",
    "load_mmap = True\n",
    "if not load_mmap:\n",
    "    mc_fpath = result_data_dir + '/mc.avi'\n",
    "    fname_new = cm.save_memmap([mc_fpath], base_name='memmap_',\n",
    "                                order='C', border_to_0=0, dview=dview)\n",
    "else:\n",
    "    fname_new = '/home/prez/data//2019-08/habituation/2019-08-27/trial/E-BL/Session1/H13_M13_S44/memmap__d1_240_d2_376_d3_1_order_C_frames_55101_.mmap'\n",
    "\n",
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some summary images (correlation and peak to noise) while downsampling temporally 5x to speedup the process and avoid memory overflow\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(images[::5], gSig=3, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "\n",
    "#Plot the results of the correlation/PNR projection\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(2, 2, 1); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
    "plt.subplot(2, 2, 2); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')\n",
    "plt.savefig(result_data_dir + '/' + 'pnr.svg', edgecolor='w', format='svg', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CNMFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frate = 20\n",
    "opts_dict = {\n",
    "  'fr': frate,\n",
    "  'use_cuda' : True,\n",
    "  'memory_fact': 1.0,\n",
    "  'decay_time': 0.4,\n",
    "  'splits_rig': 20,  # for parallelization split the movies in num_splits chunks across time\n",
    "  'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "  'K': None, # upper bound on number of components per patch, in general None\n",
    "  'gSig': [2, 2], # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "  'gSiz': [9, 9], # average diameter of a neuron, in general 4*gSig+1\n",
    "  #'gSig': [3, 3], # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "  #'gSiz': [15, 15], # average diameter of a neuron, in general 4*gSig+1\n",
    "  'merge_thr': 0.65, # merging threshold, max correlation allowed\n",
    "  'p': 1, # order of the autoregressive system\n",
    "  'tsub': 2, # downsampling factor in time for initialization\n",
    "  'ssub': 2, # downsampling factor in space for initialization\n",
    "  'rf': 40, # half-size of the patches in pixels\n",
    "  'stride': 20, # overlap between the patches in pixels (keep it at least large as gSiz)\n",
    "  'only_init': True,    # set it to True to run CNMF-E\n",
    "  'nb': 1, # number of background components (rank) if positive,\n",
    "#             else exact ring model with following settings\n",
    "#             gnb= 0: Return background as b and W\n",
    "#             gnb=-1: Return full rank background B\n",
    "#             gnb<-1: Don't return background\n",
    "\n",
    "  'nb_patch': 0,# number of background components (rank) per patch if gnb>0\n",
    "  'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "  'low_rank_background': None, # leaves background of each patch intact True performs global low-rank approximation if gnb>0\n",
    "\n",
    "  'update_background_components': True,  # sometimes setting to False improve the results\n",
    "  'min_corr': 0.8, # min peak value from correlation image\n",
    "  'min_pnr': 8, # min peak to noise ration from PNR image\n",
    "  'normalize_init': False,               # just leave as is\n",
    "  'center_psf': True,                    # leave as is for 1 photon\n",
    "  'ssub_B': 2, # downsampling factor for background\n",
    "  'ring_size_factor': 1.4, # radius of ring is gSiz*ring_size_factor\n",
    "  'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "  'border_pix': 0 # number of pixels to not consider in the borders)\n",
    "}\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# Perform CNMF\n",
    "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=None, params=opts)\n",
    "cnm.fit(images)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "The components are evaluated in three ways:\n",
    "- the shape of each component must be correlated with the data\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "\n",
    "\n",
    "min_SNR = 3            # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.8    # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worst quality)\n",
    "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
    "                           'rval_thr': r_values_min,\n",
    "                           'use_cnn': False})\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "\n",
    "print(' ***** ')\n",
    "print('Number of total components: ', len(cnm.estimates.C))\n",
    "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronsToPlot = 20\n",
    "\n",
    "DeconvTraces = cnm.estimates.S\n",
    "RawTraces = cnm.estimates.C\n",
    "SFP = cnm.estimates.A\n",
    "SFP_dims = list(dims)\n",
    "SFP_dims.append(SFP.shape[1])\n",
    "print('Spatial foootprints dimensions (height x width x neurons): ' + str(SFP_dims))\n",
    "\n",
    "numNeurons = SFP_dims[2]\n",
    "\n",
    "SFP = np.reshape(SFP.toarray(), SFP_dims, order='F')\n",
    "\n",
    "maxRawTraces = np.amax(RawTraces)\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "#plt.subplot(341);\n",
    "#plt.subplot(345); plt.plot(mc.shifts_rig); plt.title('Motion corrected shifts')\n",
    "plt.subplot(3,4,9);\n",
    "plt.subplot(3,4,2); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
    "plt.subplot(3,4,6); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')\n",
    "plt.subplot(3,4,10); plt.imshow(np.amax(SFP,axis=2)); plt.colorbar(); plt.title('Spatial footprints')\n",
    "\n",
    "plt.subplot(2,2,2); plt.figure; plt.title('Example traces (first 50 cells)')\n",
    "plot_gain = 10 # To change the value gain of traces\n",
    "if numNeurons >= neuronsToPlot:\n",
    "  for i in range(neuronsToPlot):\n",
    "    if i == 0:\n",
    "      plt.plot(RawTraces[i,:],'k')\n",
    "    else:\n",
    "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "else:\n",
    "  for i in range(numNeurons):\n",
    "    if i == 0:\n",
    "      plt.plot(RawTraces[i,:],'k')\n",
    "    else:\n",
    "      trace = RawTraces[i,:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "\n",
    "plt.subplot(2,2,4); plt.figure; plt.title('Deconvolved traces (first 50 cells)')\n",
    "plot_gain = 20 # To change the value gain of traces\n",
    "if numNeurons >= neuronsToPlot:\n",
    "  for i in range(neuronsToPlot):\n",
    "    if i == 0:\n",
    "      plt.plot(DeconvTraces[i,:],'k')\n",
    "    else:\n",
    "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "else:\n",
    "  for i in range(numNeurons):\n",
    "    if i == 0:\n",
    "      plt.plot(DeconvTraces[i,:],'k')\n",
    "    else:\n",
    "      trace = DeconvTraces[i,:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "\n",
    "# Save summary figure\n",
    "plt.savefig(result_data_dir + '/' + 'summary_figure.svg', edgecolor='w', format='svg', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the timestamps for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mstime = []\n",
    "sessionLengths = []\n",
    "for vid_dir in session_local_dir.keys():\n",
    "  with open(vid_dir + '/timestamp.dat') as f:\n",
    "    camNum, frameNum, sysClock, buffer = np.loadtxt(f, dtype='float', comments='#', skiprows=1, unpack = True)\n",
    "  camNumber = camNum[0]\n",
    "  mstime_idx = np.where(camNum == camNumber)\n",
    "  mstime = mstime + sysClock[mstime_idx]\n",
    "  sessionLengths.append(length(mstime_idx))\n",
    "mstime[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_end = time.time()\n",
    "\n",
    "analysis_duration = analysis_end - analysis_start\n",
    "\n",
    "print('Done analyzing. This took a total ' + str(analysis_duration) + ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Save the results in HDF5 format\"\"\"\n",
    "\n",
    "save_hdf5 = True\n",
    "if save_hdf5:\n",
    "  cnm.save(result_data_dir + 'analysis_results.hdf5')\n",
    "\n",
    "\"\"\"# Save the results in Matlab format\"\"\"\n",
    "\n",
    "save_mat = True\n",
    "if save_mat:\n",
    "  from scipy.io import savemat\n",
    "\n",
    "  results_dict = {\n",
    "                #'dirName': path_to_analyze,\n",
    "                'numFiles': 1,\n",
    "                'framesNum': len(RawTraces[1]),\n",
    "                'maxFramesPerFile': 1000,\n",
    "                'height': dims[0],\n",
    "                'width': dims[1],\n",
    "                'camNumber': camNumber,\n",
    "                 #'time': mstime,\n",
    "                #'sessionLengths': sessionLengths,\n",
    "                #'analysis_time': analysis_time,\n",
    "                'meanFrame': [], #TO DO\n",
    "                'Centroids': [], #TO DO\n",
    "                'CorrProj': cn_filter,\n",
    "                'PeakToNoiseProj': pnr,\n",
    "                'RawTraces': RawTraces.conj().transpose(), #swap time x neurons dimensions\n",
    "                #'FiltTraces': cnm.estimates.F_dff,\n",
    "                #'DeconvTraces': cnm.estimates.S.conj().transpose(),\n",
    "                'SFPs': SFP,\n",
    "                'numNeurons': SFP_dims[2],\n",
    "                #'analysis_duration': analysis_duration\n",
    "                }\n",
    "\n",
    "  SFPperm = np.transpose(SFP,[2,0,1])\n",
    "  sio.savemat(result_data_dir + '/SFP.mat', {'SFP': SFPperm})\n",
    "  sio.savemat(result_data_dir + '/ms.mat', {'ms': results_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.F_dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the cluster\n",
    "cm.stop_server(dview=dview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
